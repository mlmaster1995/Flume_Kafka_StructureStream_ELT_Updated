### mysql commands
// create a database and table for vmstat source
mysql> CREATE DATABASE IF NOT EXISTS chrisy;
mysql> DROP TABLE IF EXITS chrisy.fromStream;
mysql> CREATE TABLE IF NOT EXISTS chrisy.fromStream (row_id INT PRIMARY KEY AUTO_INCREMENT NOT NULL, topic VARCHAR(10), time TIMESTAMP, r VARCHAR(10), b VARCHAR(10), swpd VARCHAR(10), free VARCHAR(10), buff VARCHAR(10), cache VARCHAR(10), si VARCHAR(10), so VARCHAR(10), bi VARCHAR(10), bo VARCHAR(10), in_val VARCHAR(10), cs VARCHAR(10), us VARCHAR(10), sy VARCHAR(10), id VARCHAR(10), wa VARCHAR(10), st VARCHAR(10));

// create database and table for twitter stream source
mysql> DROP TABLE IF EXISTS chrisy.fromTweet;
mysql> CREATE TABLE IF NOT EXISTS chrisy.fromTweet (row_id INT PRIMARY KEY AUTO_INCREMENT NOT NULL, tweet_time VARCHAR(50), user_id VARCHAR(50), full_name VARCHAR(100), tweet_id VARCHAR(50), tweet_source VARCHAR(50), is_truncated VARCHAR(5), is_rt VARCHAR(5), tweet_text TEXT);

### Kafka commands for "twitter" data srouce
// start avro consumer
$ bin./kafka-avro-console-consumer --bootstrap-server localhost:9101 --topic tweetAvro
// create a new tweet topic
$ kafka-topics.sh --create --topic tweet --zookeeper localhost:2181 --partitions 1 --replication-factor 1
// start consumer and producer
$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic tweet --from-beginning
$ kafka-console-producer.sh --broker-list localhost:9092 --topic tweet
// start toKafka producer and consumer
$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic toKafka
$ kafka-console-producer.sh --broker-list localhost:9092 --topic toKafka

### Kafka & Flume commands for "vmstat" data source
// list topics
$ kafka-topics.sh --list --zookeeper localhost:2181
// create a topic
$ kafka-topics.sh --create --topic exec --zookeeper localhost:2181 --partitions 1 --replication-factor 1
// describe a topic
$ kafka-topics.sh --describe --topic exec --zookeeper localhost:2181
// start a producer
$ kafka-console-producer.sh --broker-list localhost:9092 --topic exec
// start a consumer
$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic exec
// drop a topic
$ kafka-topics.sh --zookeeper localhost:2181  --topic exec --delete
// run flume bash
flume-ng agent -n agt -f <path to flume conf file>


