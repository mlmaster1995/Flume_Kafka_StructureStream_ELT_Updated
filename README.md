## ETL Data Pipeline OOP With Kafka And Spark
![Hex.pm](https://img.shields.io/hexpm/l/plug?logo=Apache&logoColor=%23ff0000&style=flat-square)

### Table of Contents
* [About the Project](#about-the-project)
* [What's New](#what's-new)
* [Pipelines](#pipelines)  
* [Built With](#built-with)
* [Project Content](#project-content)
* [Structure Data Samples](#structure-data-samples)
* [Contact](#contact)

### About The Project
This project is updated from [Stream Data Pipeline with Flume Kafka StructureStream](https://github.com/mlmaster1995/Flume_Kafka_StructureStream_ELT) 
conducted in 2020, but this work is developed with newer version of spark and kafka. The whole project is deveoped and tested in the centOS7 VM configured with all technologies
as [Built With](#built-with).

### What's New
* Newer version of Kafka and Spark in Scala 2.12;
* Add twitter stream source;
* Add COVID-19 batch data source;   
* Add Kafka Producer in Scala;
* Add Kafka Consumer in Scala;   
* Add Avro Schema to the tweet stream source;  
* Add three more sinks including mySQL, HiveTable, MongoDB;
* Upgrade to an Object-Oriented Project;

### Pipelines
* Data Sources: 
    1. Real-time system information stream is generated by the linux command ```$ vmstate 1``` which is setup in the flume agent configuration file ```vmstat_flume_kafka.conf```. 
    2. Real-time twitter stream is generated by calling twitter4j api, and the stream is redirected into the kafka producer which could be configured by three different modes (```fire-and-foreget, sync, async```) 
       and also put avro schema into the tweet data. All these configuration and setup are in the application folder ```TwitterStreamToKafkaProducer```.
    3. Batch COVID-19 data is generated by calling [CCODWG api](https://opencovid.ca/about/) and scheduled by Apache airflow. The data is redirected into the basic kafka producer and the DAG is 
    defined in the folder ```Covid19ToKafkaProducer```
    
* Pipeline Structure:

![Big Data Flow Charts](https://user-images.githubusercontent.com/55723894/109090676-5aeaf980-76e1-11eb-856a-40bc4ccdff49.jpeg)

* Pipeline List:


    |    Sources          |                  Pipelines                            |                               Sinks                          |
    | ------------------- | ----------------------------------------------------- | ------------------------------------------------------------ |
    |    vmstat           |   flume => kafka producer => spark structured stream  |   console/ hdfs/ hive table/ kafka producer/ mongoDB/ mySQL  |
    | tweet stream        |   kafka producer => spark structured stream           |   console/ hdfs/ hive table/ kafka producer/ mongoDB/ mySQL  |
    | tweet stream        |   kafka producer + Schema Registry                    |   confluent kafka-avro-consumer/ kafka consumer              |
    | covid19 batch data  |   kafka producer => spark structured stream           |   console/ hdfs/ kafka producer                              |
    | covid19 batch data  |   kafka producer                                      |   kafka consumer                                             |

### Built With
* [Scala 2.12.10](https://www.scala-lang.org/download/2.12.10.html)
* [Apache Spark 3.0.1](https://spark.apache.org/docs/2.1.1/)
* [Apache Flume 1.9.0](https://flume.apache.org/releases/1.5.2.html)
* [Apache Kafka 2.7.0](https://kafka.apache.org/0102/documentation.html)
* [Apache Airflow 2.0.0](https://airflow.apache.org/)  
* [Apache Hadoop 2.7.7](https://hadoop.apache.org/)
* [Apache Hive 2.3.8](https://hive.apache.org/)
* [Confluent Schema Registry (Community Platform 6.1.0)](https://github.com/confluentinc/schema-registry)  
* [Twitter4j 4.0.7](http://twitter4j.org/en/index.html)
* [MongoDB 4.2](https://www.mongodb.com/)
* [MySQL 8.0.x](https://www.mysql.com/)

### Project Content

    ├── Covid19ToKafkaProducer                    # Airflow DAG for COVID-19 batch data
    ├── KafkaConsumer                             # KakfaConsumer application for tweet stream and COVID-19 data sources
    ├── KafkaSparkUnit                            # Spark extract, transform and load application 
    ├── TwitterStreamToKafkaProducer              # Twitter Stream to Kafka application
    ├── create-database-table.sql                 # SQL script for create the database and tables in mySQL
    ├── start-kafkaConsumer.sh                    # Bash script to run scala application KafkaConsumer
    ├── start-spark-kafka-unit.sh                 # Bash script to submit spark application KafkaSparkUnit
    ├── start-tweetStream-to-kafkaProducer.sh     # Bash script to run scala application KafkaConsumer
    ├── start-vmstats-with-flume.sh               # Bash script to run flume for vmstat data stream
    ├── vmstat_flume_kafka.conf                   # Flume agent configuration file

### Structure Data Samples
**NOTE**: Sensitive Data Is Hidden Or Modified In The Following Samples. 

* Pipeline: vmstat -> flume -> kafka -> spark structured streaming -> mySQL

 
    | row_id | topic | time                | r    | b    | swpd | free   | buff | cache   | si   | so   | bi   | bo   | in_val | cs   | us   | sy   | id   | wa   | st   |
    |--------|-------|---------------------|------|------|------|--------|------|---------|------|------|------|------|--------|------|------|------|------|------|------|
    |      1 | exec  | 2021-02-02 10:43:02 | 1    | 2    | 3    | 4      | 5    | 6       | 7    | 8    | 9    | 10   | 11     | 12   | 13   | 14   | 15   | 16   | 17   |
    |      2 | exec  | 2021-02-02 10:56:47 | 0    | 0    | 8    | 301620 | 1144 | 8950572 | 0    | 0    | 0    | 35   | 1706   | 1672 | 6    | 2    | 92   | 0    | 0    |
    |      3 | exec  | 2021-02-02 10:56:47 | 0    | 0    | 8    | 301176 | 1144 | 8950576 | 0    | 0    | 0    | 0    | 1469   | 1540 | 4    | 2    | 95   | 0    | 0    |
    |      4 | exec  | 2021-02-02 10:56:47 | 1    | 0    | 8    | 247564 | 1144 | 8950612 | 0    | 0    | 0    | 0    | 3564   | 3661 | 15   | 4    | 81   | 0    | 0    |
    |      5 | exec  | 2021-02-02 10:56:50 | 2    | 0    | 8    | 170608 | 1144 | 8919396 | 0    | 0    | 0    | 0    | 5363   | 4051 | 35   | 5    | 60   | 0    | 0    |
   

* Pipeline: tweet stream -> kafka -> spark structured streaming -> mySQL


    | row_id | tweet_time                   | user_id  | full_name           | tweet_id  | tweet_source        | is_truncated | is_rt | tweet_text                         |
    |--------|------------------------------|----------|---------------------|-----------|---------------------|--------------|-------|------------------------------------|
    |      1 | Fri Feb 12 20:04:55 EST 2021 |   ...    |      ...            |   ...     | Twitter for iPhone  | false        | false | just ordered ... 🥰 ...       ...  |
    |      2 | Fri Feb 12 20:04:55 EST 2021 |   ...    | chrisy 🌼@pptyaacy  |   ...     | Twitter for Android | false        | false | @bluexjjkyu okeyyy,           ...  |
    |      3 | Fri Feb 12 20:04:55 EST 2021 |   ...    |      ...            |   ...     | Twitter for iPhone  | false        | false | RT @uhprome: I really         ...  |
    |      4 | Fri Feb 12 20:04:55 EST 2021 |   ...    |      ...            |  ...      | Twitter for iPhone  | false        | false | RT @thesecret: Every          ...  |
    |      5 | Fri Feb 12 20:04:55 EST 2021 |   ...    |      ...            |   ...     | Twitter for iPhone  | false        | false | RT @ferbIatin: the            ...  |

* Pipeline: tweet stream -> kafka -> spark structred streaming -> mongoDB
  

      {
        "_id" : ObjectId("60271b6f6a142c2014fdc296"),
        "tweet_time" : "Fri Feb 12 19:20:53 EST 2021",
        "user_id" : "...",
        "full_name" : "...",
        "tweet_id" : "...",
        "tweet_source" : "Twitter for iPhone",
        "is_truncated" : "false",
        "is_rt" : "false",
        "tweet_text" : "First Time She Put Dat Pussy On Me I Put Her In A Benz 🤞🏽"
      }

* Pipeline: tweet stream -> kafka + Schema Registry -> Confluent Kafka Avro Consumer 
    
     
     {"tweetdate":"Sat Feb 20 19:23:25 EST 2021","userID":{"long":...},"fullName":{"string":"Aphrodi\uD83D\uD..."},"tweetID":{"long":...},"tweetSource":{"string":"Twitter for iPhone"},"isTruncated":{"boolean":false},"isRT":{"boolean":false},"tweet":{"string":"RT @deeptrusts: I want someo ..."}}
     
     {"tweetdate":"Sat Feb 20 19:23:25 EST 2021","userID":{"long":...},"fullName":{"string":"Ro ♒\uD83D\uDC96..."},"tweetID":{"long":...},"tweetSource":{"string":"Twitter for iPhone"},"isTruncated":{"boolean":false},"isRT":{"boolean":false},"tweet":{"string":"RT @feelxpain: i fucking fac ..."}}
     
     {"tweetdate":"Sat Feb 20 19:23:25 EST 2021","userID":{"long":...},"fullName":{"string":"nico._.macedo@ni..."},"tweetID":{"long":...},"tweetSource":{"string":"Twitter for Android"},"isTruncated":{"boolean":false},"isRT":{"boolean":false},"tweet":{"string":"@mukti_alin NFR lbinoBateon ..."}}



### Contact
* C. Young: kyang3@lakeheadu.ca
